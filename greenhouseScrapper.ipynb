{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing Libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data = {\n",
    "    'company_id': [1],\n",
    "    'company_name': ['ACLU'],\n",
    "    'company_url': ['https://boards.greenhouse.io/aclu']\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "company_df = pd.DataFrame(company_data)\n",
    "\n",
    "# List to hold all job data\n",
    "job_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, company_row in company_df.iterrows():\n",
    "    company_id = company_row['company_id']\n",
    "    company_name = company_row['company_name']\n",
    "    company_url = company_row['company_url']\n",
    "\n",
    "    # Initialize WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Navigate to the company's job site\n",
    "    driver.get(company_url)\n",
    "\n",
    "    # Get the page source and parse with BeautifulSoup\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find all job postings\n",
    "    job_posts = soup.find_all('tr', class_='job-post')\n",
    "\n",
    "    # Extract data from each job post\n",
    "    for job in job_posts:\n",
    "        try:\n",
    "            # Extract the anchor tag that contains job details\n",
    "            job_link = job.find('a')\n",
    "            if job_link is None:\n",
    "                print(\"No job link found.\")\n",
    "                continue\n",
    "\n",
    "            # Extract job title\n",
    "            job_title_element = job_link.find('p', class_='body body--medium')\n",
    "            job_title = job_title_element.text.strip() if job_title_element else 'N/A'\n",
    "\n",
    "            # Extract job URL\n",
    "            job_url = job_link['href'] if job_link else 'N/A'\n",
    "\n",
    "            # Extract job location\n",
    "            location_element = job_link.find('p', class_='body body__secondary body--metadata')\n",
    "            location = location_element.text.strip() if location_element else 'N/A'\n",
    "\n",
    "            # Add job data to the list\n",
    "            job_data.append({\n",
    "                'company_id': company_id,\n",
    "                'company_name': company_name,\n",
    "                'company_url': company_url,\n",
    "                'job_title': job_title,\n",
    "                'job_url': job_url,\n",
    "                'location': location\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error while extracting job data:\", e)\n",
    "            continue\n",
    "\n",
    "    # Quit the WebDriver after scraping\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_url</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_url</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>https://boards.greenhouse.io/aclu</td>\n",
       "      <td>Deputy Organizing Director</td>\n",
       "      <td>https://job-boards.greenhouse.io/aclu/jobs/756...</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>https://boards.greenhouse.io/aclu</td>\n",
       "      <td>Senior Campaign Strategist</td>\n",
       "      <td>https://job-boards.greenhouse.io/aclu/jobs/761...</td>\n",
       "      <td>Washington, District of Columbia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>https://boards.greenhouse.io/aclu</td>\n",
       "      <td>Senior Campaign Strategist, Democracy</td>\n",
       "      <td>https://job-boards.greenhouse.io/aclu/jobs/744...</td>\n",
       "      <td>Washington, District of Columbia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>https://boards.greenhouse.io/aclu</td>\n",
       "      <td>Senior Digital Organizing Specialist</td>\n",
       "      <td>https://job-boards.greenhouse.io/aclu/jobs/755...</td>\n",
       "      <td>Washington, District of Columbia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>https://boards.greenhouse.io/aclu</td>\n",
       "      <td>Senior Digital Organizing Specialist</td>\n",
       "      <td>https://job-boards.greenhouse.io/aclu/jobs/755...</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company_id company_name                        company_url  \\\n",
       "73           1         ACLU  https://boards.greenhouse.io/aclu   \n",
       "74           1         ACLU  https://boards.greenhouse.io/aclu   \n",
       "75           1         ACLU  https://boards.greenhouse.io/aclu   \n",
       "76           1         ACLU  https://boards.greenhouse.io/aclu   \n",
       "77           1         ACLU  https://boards.greenhouse.io/aclu   \n",
       "\n",
       "                                job_title  \\\n",
       "73             Deputy Organizing Director   \n",
       "74             Senior Campaign Strategist   \n",
       "75  Senior Campaign Strategist, Democracy   \n",
       "76   Senior Digital Organizing Specialist   \n",
       "77   Senior Digital Organizing Specialist   \n",
       "\n",
       "                                              job_url  \\\n",
       "73  https://job-boards.greenhouse.io/aclu/jobs/756...   \n",
       "74  https://job-boards.greenhouse.io/aclu/jobs/761...   \n",
       "75  https://job-boards.greenhouse.io/aclu/jobs/744...   \n",
       "76  https://job-boards.greenhouse.io/aclu/jobs/755...   \n",
       "77  https://job-boards.greenhouse.io/aclu/jobs/755...   \n",
       "\n",
       "                                           location  \n",
       "73                New York, New York, United States  \n",
       "74  Washington, District of Columbia, United States  \n",
       "75  Washington, District of Columbia, United States  \n",
       "76  Washington, District of Columbia, United States  \n",
       "77                New York, New York, United States  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert job data to a pandas DataFrame\n",
    "job_df = pd.DataFrame(job_data)\n",
    "\n",
    "# Output the DataFrame\n",
    "job_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posting date not found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://job-boards.greenhouse.io/scaleai/jobs/4461977005'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Look for the posting date\n",
    "# This will depend on the specific HTML structure of the job posting page\n",
    "posting_date = soup.find('div', class_='posting-date')  # Adjust the class based on the actual HTML\n",
    "if posting_date:\n",
    "    print(\"Job Posting Date:\", posting_date.text)\n",
    "else:\n",
    "    print(\"Posting date not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
